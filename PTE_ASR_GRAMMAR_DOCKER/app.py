
import os
import shutil
import tempfile
from typing import List, Dict, Any
from fastapi import FastAPI, UploadFile, File, HTTPException
from pydantic import BaseModel
import language_tool_python
import nemo.collections.asr as nemo_asr
import torch

app = FastAPI(title="PTE ASR & Grammar Service")

# --- Global Models ---
print("Loading NVIDIA Parakeet model (parakeet-tdt-0.6b-v2)...")
try:
    # Load NVIDIA Parakeet model
    asr_model = nemo_asr.models.ASRModel.from_pretrained(model_name="nvidia/parakeet-tdt-0.6b-v2")
    
    # Move to GPU if available, else CPU
    device = "cuda" if torch.cuda.is_available() else "cpu"
    asr_model = asr_model.to(device)
    asr_model.eval()
    print(f"Parakeet model loaded on {device}.")
except Exception as e:
    print(f"Error loading Parakeet: {e}")
    asr_model = None

print("Loading LanguageTool...")
try:
    lang_tool = language_tool_python.LanguageTool('en-US')
    print("LanguageTool loaded.")
except Exception as e:
    print(f"Error loading LanguageTool: {e}")
    lang_tool = None


# --- Data Models ---
class GrammarRequest(BaseModel):
    text: str

class GrammarResponse(BaseModel):
    matches: List[str]

class TranscribeResponse(BaseModel):
    text: str
    language: str
    segments: List[Dict[str, Any]]

# --- Endpoints ---

@app.get("/health")
def health_check():
    return {
        "status": "ok",
        "parakeet": asr_model is not None,
        "language_tool": lang_tool is not None
    }

@app.post("/transcribe", response_model=TranscribeResponse)
async def transcribe_audio(audio: UploadFile = File(...)):
    """
    Transcribe audio file using NVIDIA Parakeet TDT.
    Returns: text, detected language, and word-level segments.
    """
    content = await audio.read()
    print(f"Received transcription request for: {audio.filename} ({len(content)} bytes)")
    if not asr_model:
        print("Error: Parakeet model not loaded")
        raise HTTPException(status_code=503, detail="Parakeet model not loaded")

    # Save uploaded file to temp location
    temp_path = None
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_file:
            temp_path = temp_file.name
            temp_file.write(content)
        
        print(f"Transcribing {temp_path} with Parakeet TDT...")
        # Transcribe with Parakeet
        outputs = asr_model.transcribe([temp_path], timestamps=True)
        
        if not outputs:
            raise Exception("No transcription generated by the model.")
            
        # NeMo transcribe can return List[List[Hypothesis]] or List[Hypothesis]
        if isinstance(outputs[0], list):
            result = outputs[0][0]
        else:
            result = outputs[0]
        
        print(f"Transcription result type: {type(result)}")
        print(f"Transcription text: {result.text}")
        
        full_text = result.text
        # Parakeet-TDT returns a Hypothesis object with a timestamp dict
        word_timestamps = []
        if hasattr(result, 'timestamp') and isinstance(result.timestamp, dict):
            word_timestamps = result.timestamp.get('word', [])
        elif hasattr(result, 'timestep') and isinstance(result.timestep, dict):
            word_timestamps = result.timestep.get('word', [])
        
        print(f"Extracted {len(word_timestamps)} word timestamps.")
        if word_timestamps:
            print(f"First word timestamp sample: {word_timestamps[0]}")
        
        # Since TDT might not provide segments directly like Whisper, 
        # we'll create a single segment containing all words for now.
        # This keeps the validator's loop working.
        
        words_data = []
        for word_info in word_timestamps:
            # Handle both dict-like and object-like access
            if isinstance(word_info, dict):
                word_val = word_info.get("word", word_info.get("text", ""))
                start_val = word_info.get("start", 0)
                end_val = word_info.get("end", 0)
            else:
                word_val = getattr(word_info, "word", getattr(word_info, "text", ""))
                start_val = getattr(word_info, "start", 0)
                end_val = getattr(word_info, "end", 0)
                
            words_data.append({
                "word": str(word_val).strip(),
                "start": float(start_val),
                "end": float(end_val)
            })
            
        segments = [{
            "start": words_data[0]["start"] if words_data else 0,
            "end": words_data[-1]["end"] if words_data else 0,
            "text": full_text,
            "words": words_data
        }]
        
        return {
            "text": full_text.strip(),
            "language": "en", # Parakeet 0.6b-v2 is primarily English
            "segments": segments
        }
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Transcription failed: {str(e)}")
    finally:
        if temp_path and os.path.exists(temp_path):
            os.remove(temp_path)

@app.post("/grammar", response_model=GrammarResponse)
async def check_grammar(req: GrammarRequest):
    """
    Check grammar of provided text using LanguageTool.
    """
    if not lang_tool:
        raise HTTPException(status_code=503, detail="LanguageTool not loaded")

    try:
        matches = lang_tool.check(req.text)
        formatted_matches = []
        for match in matches:
            context = match.context
            if len(context) > 50:
                context = context[:47] + "..."
            issue = f"[{match.ruleId}] {match.message} near '{context}'"
            formatted_matches.append(issue)
        
        return {"matches": formatted_matches}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Grammar check failed: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
