# Targeted MFA Optimization for Describe Image and Retell Lecture

This plan will significantly speed up the evaluation for "Describe Image" and "Retell Lecture" tasks by using only the Indian MFA model, while maintaining the full dual-accent analysis (Indian + US ARPA) for "Read Aloud" and "Repeat Sentence" as requested.

## **Proposed Implementation**

### **1. Update Alignment Logic in [validator.py](file:///c:/Users/Acer/DataScience/PTE/api/validator.py)**
- Modify `align_and_validate` and `align_and_validate_gen` to accept an optional `accents` parameter (a list of strings).
- If `accents` is provided, the system will only initialize and run alignment for those specific models.
- If not provided, it will default to using all available models (`Indian` and `US_ARPA`).
- Update the "anchor" logic to dynamically pick the first available accent from the results if `US_ARPA` is not present.

### **2. Modify Task Runners in [app.py](file:///c:/Users/Acer/DataScience/PTE/api/app.py)**
- **Describe Image**: Update `run_image_evaluation_job` to call `align_and_validate(..., accents=['Indian'])`.
- **Retell Lecture**: Update `run_lecture_evaluation_job` to call `align_and_validate(..., accents=['Indian'])`.
- **Read Aloud/Repeat Sentence**: Keep `run_mfa_job` and `check_stream` calls as they are (no `accents` parameter passed), so they continue to use both models for maximum accuracy.

## **Benefits**
- **Speed**: Processing time for Describe Image and Retell Lecture will be reduced by ~50% because only one Docker container will be launched instead of two.
- **Consistency**: Read Aloud will still benefit from the dual-accent comparison.
- **Accuracy**: Describe Image and Retell Lecture will specifically target the Indian accent as requested.

Would you like me to implement this targeted optimization?