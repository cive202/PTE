I will implement the CPU-only wav2vec2 Docker service as described. This involves creating a dedicated microservice for phoneme recognition to offload processing from the main Flask app and ensure environment isolation.

### **Phase 1: Service Creation**
1.  **Create Directory**: `wav2vec2_service/` in the project root.
2.  **Create `requirements.txt`**:
    *   Include `torch`, `torchaudio`, `transformers`, `librosa`, `soundfile`, `flask`.
    *   Explicitly specify CPU-only torch to save image size (e.g., `--index-url https://download.pytorch.org/whl/cpu` logic in Dockerfile or pip command).
3.  **Create `phoneme_model.py`**:
    *   Load `facebook/wav2vec2-lv60-espeak-cv-ft` on CPU.
    *   Implement `get_phonemes` with `librosa` loading, slicing logic, and `torch.no_grad()` inference.
4.  **Create `app.py`**:
    *   Flask API with `/phonemes` endpoint.
    *   Handle file upload and start/end parameters.
5.  **Create `Dockerfile`**:
    *   Base: `python:3.10-slim`.
    *   Install system dependencies (libsndfile for soundfile).
    *   Install Python requirements.
    *   Expose port 8001.

### **Phase 2: Build & Run**
6.  **Build Docker Image**: `docker build -t wav2vec2-phoneme-cpu .`
7.  **Run Container**: `docker run -d -p 8001:8001 --name wav2vec2-service wav2vec2-phoneme-cpu`

### **Phase 3: Integration**
8.  **Update `api/validator.py`**:
    *   Replace the local `PhonemeASR` class/calls with `call_phoneme_service` function.
    *   Implement HTTP POST logic to `http://localhost:8001/phonemes`.
    *   Keep the existing logic for PER scoring and validator flow, just swapping the inference engine.

### **Phase 4: Verification**
9.  **Test Endpoint**: Curl the new service to ensure it returns phonemes.
10. **Test Read Aloud**: Run a full task in the browser to verify the end-to-end flow works with the new microservice.
